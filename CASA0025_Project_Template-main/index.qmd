---
title: CROPINVEST
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

![](Captnknure.JPG)

## Project Summary 

CROPINVEST - Crop Yield Estimator for the State of North Dakota, USA

### Problem Statement 

What is the problem you’re trying to address using this application? 

### End User 

Who are you building this application for? How does it address a need this community has?

### Data

Datasets that we have used & the relevant data from the dataset which we have used are described below in detail:-

1. **United States Census Bureau TIGER Dataset**
   It contains the boundary information i.e. counties of states which are the primary legal divisions units of US states.
    - *Dataset:* ee.ImageCollection("TIGER/2016/Counties")
    - *Dataset Provider:* United States Census Bureau
    - *Data Used for our Study:* `STATEFP` parameter of the dataset which provides the State FIPS code & the North Dakota value is used.
<br><br>     
2. **USDA NASS Cropland Data Layers**
   It is a crop-specific land cover data layer created annually for the continental United States using moderate resolution satellite imagery and extensive agricultural ground truth.
    - *Dataset:* ee.FeatureCollection("USDA/NASS/CDL")
    - *Dataset Provider:* USDA National Agricultural Statistics Service
    - *Data Used for our Study:* `cropland` values for different crops of our study are used Wheat, Corn & Soybean Values provided from the Cropland Table.
<br><br>     
3. **MOD13Q1.061 Terra Vegetation Indices 16-Day Global**
   It provides Normalized Difference Vegetation Index (NDVI) value on a per pixel basis. 
    - *Dataset:* ee.ImageCollection("MODIS/061/MOD13Q1")
    - *Dataset Provider:* NASA LP DAAC at the USGS EROS Center
    - *Data Used for our Study:* `NDVI` parameter of the dataset which provides the Normalized Difference Vegetation Index.
<br><br>     
4. **GRIDMET:Gridded Surface Meteorological Dataset**
   It provides the high spatial resolution (~4-km) daily surface fields of temperature, precipitation, winds, humidity and radiation across the contiguous United States from 1979. 
    - *Dataset:* ee.ImageCollection("IDAHO_EPSCOR/GRIDMET")
    - *Dataset Provider:* USDA National Agricultural Statistics Service
    - *Data Used for our Study:* `pr` parameter of the dataset which provides the 'Precipitation amount' in mm (daily total)
<br><br>      
5. **Sentinel-1 SAR GRD**
   It contains the boundary information i.e. counties of states which are the primary legal divisions units of US states.
    - *Dataset:* ee.ImageCollection("COPERNICUS/S1_GRD")
    - *Dataset Provider:* European Union/ESA/Copernicus
    - *Data Used for our Study:* `VV` parameter of the dataset which provides 'Single co-polarization, vertical transmit/vertical receive' in dB.
<br><br> 
6. **SPL3SMP_E.005 SMAP L3 Radiometer Global Daily 9km Soil Moisture**
   It provides a daily composite of global land surface conditions retrieved by the Soil Moisture Active Passive (SMAP) L-Band radiometer. The daily data here were collected from the descending (local solar time of 6 am) and ascending (local solar time of 6 pm) passes.
    - *Dataset:* ee.ImageCollection("NASA/SMAP/SPL3SMP_E/005")
    - *Dataset Provider:* Google and NSIDC
    - *Data Used for our Study:* `soil_moisture_am` & `soil_moisture_pm`parameter of the dataset which provides 'Retrieved soil moisture estimate from the disaggregated/downscaled vertical polarization brightness temperature at 9-km grid cell one at AM overpass & other at  PM overpass.in dB.
<br><br>
7. **MOD11A1.061 Terra Land Surface Temperature**
   MOD11A1 V6.1 product provides daily land surface temperature (LST) along with other parameters.
    - *Dataset:* ee.ImageCollection("NASA/SMAP/SPL3SMP_E/005")
    - *Dataset Provider:* NASA LP DAAC at the USGS EROS Center
    - *Data Used for our Study:* `LST_Day_1km` & `LST_Night_1km`parameter of the dataset which provides 'Daytime Land Surface Temperature' & Daytime Land Surface Temperature' both in Kelvin (K).
<br><br>
8. **MCD18C2.061 Photosynthetically Active Radiation Daily 3 hour**
   The MCD18C2 Version 6.1 is a Moderate Resolution Imaging Spectroradiometer (MODIS) Terra and Aqua combined Photosynthetically Active Radiation (PAR) gridded Level 3 product produced daily at 0.05 degree (5,600 meters at the equator) resolution with estimates of PAR every 3 hours. 
    - *Dataset:* ee.ImageCollection("MODIS/061/MCD18C2")
    - *Dataset Provider:* NASA LP DAAC at the USGS EROS Center
    - *Data Used for our Study:* `GMT_1200_PAR` parameter of the dataset which provides 'Total PAR at GMT 12:00'.PAR is incident solar radiation in the visible spectrum (400-700 nanometers) and is an important variable in land-surface models having use in agriculture & other scientific applications.
<br><br>
9. **MOD16A2GF.061: Terra Net Evapotranspiration**
   It includes inputs of daily meteorological reanalysis data along with MODIS remotely sensed data products such as vegetation property dynamics, albedo, and land cover.
The pixel values for the two Evapotranspiration layers (ET and PET) are the sum of all eight days within the composite period, and the pixel values for the two Latent Heat layers (LE and PLE) are the average of all eight days within the composite peri.
   - *Dataset:* ee.ImageCollection("MODIS/061/MOD16A2GF")
   - *Dataset Provider:* NASA LP DAAC at the USGS EROS Center
   - *Data Used for our Study:* `ET` parameter of the dataset which provides 'Total evapotranspiration' in kg/m^2/8day.s.
<br><br>

### Methodology

How are you using this data to address the problem?

#### **Building Random Forest Model:**

1. **Prepare original CSV including the three types of crop among several X variables and Y variable (the crop yield)**
    - *CSV Img!*
<br><br>     
2. **Prepare training/validation data**
    - Add a random attribute to the data set with a random number.
    - Split 80% of data for training and 20% of that for testing.       
<br><br> 
3. **Use the training data to train three different RF Models in GEE**
    - ee.Classifier.smileRandomForest(100, null, 1, 0.5, null, 0).setOutputMode('REGRESSION')
    - Notice ‘setOutputMode’ is set to ‘REGRESSION’. This command is the most important for running Random Forest regression models in GEE
<br><br> 
#### **Validation**
    - X variables
    - Importances
    - R2
    - RMSE

### Interface

Here is a presentation to show, how our application work:

<div style="position: relative; width: 110%; height:600px; padding-top: 56.2500%;
 padding-bottom: 0; box-shadow: 0 2px 8px 0 rgba(63,69,81,0.16); margin-top: 1.6em; margin-bottom: 0.9em; overflow: hidden;
 border-radius: 8px; will-change: transform;">
  <iframe loading="lazy" style="position: absolute; width: 100%; height: 100%; top: 0; left: 0; border: none; padding: 0;margin: 0;"
    src="https:&#x2F;&#x2F;www.canva.com&#x2F;design&#x2F;DAGCq_eFmq8&#x2F;Muz__V20V7SJUNr3EVBSEQ&#x2F;view?embed" allowfullscreen="allowfullscreen" allow="fullscreen">
  </iframe>
</div>

## The Application 

:::{.column-page}

<iframe src='https://songzimeng.users.earthengine.app/view/north-dakota-crop-yield' width='100%' height='700px'></iframe>

:::

## How it Works 

### Data Extraction Code:
- Here we use the Python environment to extract the data from different datasets using Google Earth Engine API
- Afterwards, we first use the crop-specific land cover data to distinguish different crops- wheat, soybean or corn for each county in North Dakota.
- Further, NDVI, Precipitation, SAR, Soil Moisture & other values are used to get the county-wise values from the year 2000-2024.
- Afterwards, the Yield data is obtained from the [United States Department of Agriculture](https://quickstats.nass.usda.gov/) for each of the years and a final dataset is obtained which has all the X Variables (GEOID,NDVI,PA,SAR,SMS_AM,LST_DAY,SMS_PM,LST_NIGHT,PAR,ET) & Y variable (YIELD).

```python
# Commented the line below as I have installed the gee api already
#pip install earthengine-api
import ee
ee.Authenticate()
ee.Initialize()
def processYear(year):
    # Load the CDL dataset for the given year
    dataset = ee.ImageCollection('USDA/NASS/CDL')\
                .filter(ee.Filter.date(f'{year}-01-01', f'{year}-12-31'))\
                .first()
    crop_landcover = dataset.select('cropland')

    # Filter for North Dakota counties
    #`STATEFP` parameter of the dataset which provides the State FIPS code & the North Dakota value is used.
    counties = ee.FeatureCollection('TIGER/2016/Counties')
    nd = counties.filter(ee.Filter.eq('STATEFP', '38'))

    # Identify corn areas in North Dakota
    #`cropland` values for different crops of our study are used Wheat, Corn & Soybean Values provided from the Cropland Table.
    corn = crop_landcover.eq(1).Or(crop_landcover.eq(12)).Or(crop_landcover.eq(13))
    masked_corn = crop_landcover.updateMask(corn).clipToCollection(nd)

    # Calculate NDVI for corn areas using MODIS data
    #`NDVI` parameter of the dataset and we obtain the mean over the growth period of the crop
    NDVI_dataset = ee.ImageCollection('MODIS/061/MOD13Q1')\
                    .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))
    ndvi = NDVI_dataset.select('NDVI')
    mean_ndvi = ndvi.mean().rename('NDVI')
    cornNDVI = mean_ndvi.updateMask(masked_corn)

    # Calculate precipitation using GRIDMET data
    #`pr` parameter of the dataset which provides the 'Precipitation amount' in mm (daily total)
    precipitation_dataset = ee.ImageCollection("IDAHO_EPSCOR/GRIDMET")\
                             .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))\
                             .select('pr')
    mean_precipitation = precipitation_dataset.mean().rename('PA')

    # Load Sentinel-1 C-band SAR Image Collection for the given year, select VV polarization
    #`VV` parameter of the dataset which provides 'Single co-polarization, vertical transmit/vertical receive' in dB.
    s1_dataset = ee.ImageCollection("COPERNICUS/S1_GRD")\
                   .filter(ee.Filter.eq('instrumentMode', 'IW'))\
                   .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\
                   .filter(ee.Filter.date(f'{year}-01-01', f'{year}-12-31'))\
                   .select('VV')
    mean_s1_vv = s1_dataset.mean().rename('SAR')

    # Load Radiometer Global Daily 9 km Soil Moisture AM
    #`soil_moisture_am` & `soil_moisture_pm` parameter of the dataset which provides 'Retrieved soil moisture estimate from the
    # disaggregated/downscaled vertical polarization brightness temperature at 9-km grid cell one at AM overpass & other at  PM overpass. in dB.
    smap_dataset = ee.ImageCollection("NASA/SMAP/SPL3SMP_E/005")\
                    .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))\
                    .select('soil_moisture_am')
    mean_soil_moisture = smap_dataset.mean().rename('SMS_AM')
    # Load Radiometer Global Daily 9 km Soil Moisture PM
    smapDataset_pm = ee.ImageCollection("NASA/SMAP/SPL3SMP_E/005")\
                       .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))\
                       .select('soil_moisture_am')
    meanSoilMoisture_pm = smapDataset_pm.mean().rename('SMS_PM')

    # Load MODIS Land Surface Temperature DAY
    #`LST_Day_1km` & `LST_Night_1km` parameter of the dataset which provides 'Daytime Land Surface Temperature' &
    # Nighttime Land Surface Temperature' both in Kelvin (K).
    lstDataset = ee.ImageCollection("MODIS/061/MOD11A1")\
                   .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))
    lstmean_celsius = lstDataset.select('LST_Day_1km')\
                                .mean()\
                                .multiply(0.02)\
                                .subtract(273.15)\
                                .rename('LST_DAY')

    # Load MODIS Land Surface Temperature NIGHT
    lstDataset_night = ee.ImageCollection("MODIS/061/MOD11A1")\
                         .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))
    lstmean_celsius_night = lstDataset_night.select('LST_Night_1km')\
                                              .mean()\
                                              .multiply(0.02)\
                                              .subtract(273.15)\
                                              .rename('LST_NIGHT')

    # Photosynthetically Active Radiation Daily 3-Hour
    #`GMT_1200_PAR` parameter of the dataset which provides 'Total PAR at GMT 12:00'. PAR is incident solar radiation in
    # the visible spectrum (400-700 nanometers) and is an important variable in land-surface models having use in agriculture &
    # other scientific applications.
    par_12 = ee.ImageCollection("MODIS/061/MCD18C2")\
               .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))\
               .select('GMT_1200_PAR')
    mean_par_12 = par_12.mean().rename('PAR'); # Calculate the Photosynthetically Active Radiation at 12 PM

    # Net Evapotranspiration
    # `ET` parameter of the dataset which provides 'Total evapotranspiration' in kg/m^2/8day.s.
    netevapo = ee.ImageCollection("MODIS/061/MOD16A2GF")\
                 .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))\
                 .select('ET')

    mean_netevapo = netevapo.mean().rename('ET')  # Calculate the mean Soil Moisture

    # Combine all layers
    combinedDataset = cornNDVI.addBands(mean_precipitation).addBands(mean_s1_vv).addBands(mean_soil_moisture).addBands(lstmean_celsius).addBands(meanSoilMoisture_pm).addBands(lstmean_celsius_night).addBands(mean_par_12).addBands(mean_netevapo)

    # Reduce regions and calculate mean values over the specified areas
    combined_mean = combinedDataset.reduceRegions(
     collection=nd,
     reducer=ee.Reducer.mean(),
     scale=30,
     tileScale=4,
     )

     # Define export parameters
    export_params = {
        'collection': combined_mean,
        'description': f'combined_{year}',
        'folder': 'GEE_Folder',
        'fileNamePrefix': f'Combined_{year}',
        'fileFormat': 'CSV',
        'selectors': ['NAME', 'GEOID', 'NDVI', 'PA', 'SAR', 'SMS_AM', 'LST_DAY', 'SMS_PM', 'LST_NIGHT', 'PAR', 'ET']
    }

    # Commented the line below as I have got the data in my drive already
    #ee.batch.Export.table.toDrive(**export_params).start()

    # Example of processing each year
    for year in range(2000, 2024):
        processYear(year)

### Methodology Code:

### Interface Code:

