[
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "",
    "section": "",
    "text": "Use this repository to host a website for your CASA0025 final project by following these stpes:\n\nclone this repository\ninstall quarto\nedit the ‘index.qmd’ file with the contents of your project\nusing terminal, navigate to the project directory and run “quarto render”\npush the changes to your github repository\non github, navigate to Settings&gt;Pages&gt;Build and Deployment. Make sure that under “Source” it says “deploy from branch”. Under “Branch”, select “Main” in the first dropdown and “Docs” under the second drop down. Then press “Save”\n\nYour website should now be available under https://{your_username}.github.io/{your_repo_name}"
  },
  {
    "objectID": "index.html#project-summary",
    "href": "index.html#project-summary",
    "title": "CROPINVEST - Crop Yield Estimator",
    "section": "Project Summary",
    "text": "Project Summary\nCROPINVEST - Crop Yield Estimator for the State of North Dakota, USA"
  },
  {
    "objectID": "index.html#problem-statement",
    "href": "index.html#problem-statement",
    "title": "CROPINVEST - Crop Yield Estimator",
    "section": "Problem Statement",
    "text": "Problem Statement\nNorth Dakota, a state in the Midwestern United States, is popular with agricultural investors for its abundant agricultural resources and vast farmland. However, the agencies like – banks, crop insurance companies, etc need a tool that can predict the crop yield value of a particular farm to ensure that they can safeguard their investment. In this regard, we create CROPINVEST, a GEE application that monitors the environment to predict crop yields, and based on these yields, we obtain the market value of the crop, which in turn can help end users (banks, crop insurance companies ,etc) to accurately and scientifically capture the farms potential to pay the crop loan amount or the risk associated with the insured crops and enable stakeholders to make informed decisions that optimize agricultural productivity, market strategies, and economic outcomes."
  },
  {
    "objectID": "index.html#end-user",
    "href": "index.html#end-user",
    "title": "CROPINVEST - Crop Yield Estimator",
    "section": "End User",
    "text": "End User\n\nInsurance Companies\n\nBased on potential crop yields, charge Insurance premiums to farmers thus mitigating financial losses from decreased production.\nManaging financial exposure if low yield or drought conditions prevail, which could lead to substantial claims from farmers.\n\nBanks\n\nUtilize it to evaluate loan feasibility for farmers and adjust interest rates based on predicted yields and associated risks.\n\nFarmer Associations\n\nUtilize it to forecast yields, plan for adverse conditions, and identify areas needing more irrigation.\n\nGovernments\n\nTo anticipate and prepare for potential crop deficits or surpluses at a county level and thus developing policies/infrastructure for the same."
  },
  {
    "objectID": "index.html#data",
    "href": "index.html#data",
    "title": "CROPINVEST - Crop Yield Estimator",
    "section": "Data",
    "text": "Data\n\nDatasets\n\nA1 - United States Census Bureau TIGER Dataset: Boundary information for U.S. counties.\nA2 - USDA NASS Cropland Data Layers: Crop-specific Land cover data.\nA3 - MOD16A2GF.061 Terra Net Evapotranspiration: Total evapotranspiration over land.\nA4 - MOD11A1.061 Terra Land Surface Temperature: Land surface temperature data.\nA5 - MOD13Q1.061 Terra Vegetation Indices 16-Day Global: Vegetation indices.\nA6 - GRIDMET: Gridded Surface Meteorological Dataset: Meteorological data.\nA7 - MCD18C2.061 Photosynthetically Active Radiation Daily 3 hour: Solar Radiation Levels.\nA8 - SPL3SMP_E.005 SMAP L3 Radiometer Global Daily 9km Soil Moisture: Soil moisture.\nA9 - *Crop Yield Data**: Contains county-wise crop yield data.USDA\nA10 - Current Crop Price Data: Uses current crop price data from Financial Times\n\n\n\nData Variables Overview\n\n\n\n\n\n\n\n\n\nData Type\nDataset\nDescription\nData Used\n\n\n\n\nGEE DATA\nA1\nCounty wise Boundary Information\nSTATEFP\n\n\nGEE DATA\nA2\nCrop-specific Land Cover Data Type\ncropland\n\n\nGEE DATA\nA3\nEvapo-Transpiration\nET\n\n\nGEE DATA\nA4\nLand Surface Temperature Day\nLST_Day_1km\n\n\nGEE DATA\nA4\nLand Surface Temperature Night\nLST_Night_1km\n\n\nGEE DATA\nA5\nNormalized Difference Vegetation Index\nNDVI\n\n\nGEE DATA\nA6\nPrecipitation\npr\n\n\nGEE DATA\nA7\nPhotosynthetically Active Radiation\nGMT_1200_PAR\n\n\nGEE DATA\nA8\nDay Soil Moisture\nsoil_moisture_am\n\n\nGEE DATA\nA8\nNight Soil Moisture\nsoil_moisture_pm\n\n\nOTHER DATA\nA9\nUSDA Crop Yield (Year Wise)\nYield\n\n\nOTHER DATA\nA10\nCrop Day Price $ - Financial Times\nPrice"
  },
  {
    "objectID": "index.html#methodology",
    "href": "index.html#methodology",
    "title": "CROPINVEST - Crop Yield Estimator",
    "section": "Methodology",
    "text": "Methodology\nPrevious studies showed that RF is an effective and universal machine learning method for crop yield prediction on a regional and global scale with high accuracy and precision and ease of use (Jeong et al., 2016.; Prasad et al., 2021).\n\nBuilding Random Forest Model:\n\nPrepare original CSV file\n\nincluding the three crops (corn, wheat, soybean) among several X variables and Y variable (the crop yield).\n\n\nPrepare training data(80%)/validation data(20%)\nUse the training data to train three different Random Forest regression Models in GEE\n\n\n\n\nValidation\nTo get the performance of our models, we can use the test data from the previous split. We used R square and Root Mean Squared Error (RMSE) to validate our models. There are some graphs showing these metrics:"
  },
  {
    "objectID": "index.html#interface",
    "href": "index.html#interface",
    "title": "CROPINVEST - Crop Yield Estimator",
    "section": "Interface",
    "text": "Interface\nCROPINVEST supports insurance companies, banks, and farmer associations with advanced features for forecasting crop yields in North Dakota for wheat, corn, and soybeans. Users can select different Crops and Years and utilize two key functionalities: a County feature to display crop yields, planting area, total production, and county-wide crop price totals via clickable maps; and a custom Area feature allowing users to draw specific regions to analyze crop yields, areas planted, and aggregate pricing. This interface ensures banks and insurance companies can assess financial risks effectively, while farmers gain crucial insights into expected yields and market conditions. Here is brief overview of how our application works:"
  },
  {
    "objectID": "index.html#the-application",
    "href": "index.html#the-application",
    "title": "CROPINVEST - Crop Yield Estimator",
    "section": "The Application",
    "text": "The Application"
  },
  {
    "objectID": "index.html#how-it-works",
    "href": "index.html#how-it-works",
    "title": "CROPINVEST - Crop Yield Estimator",
    "section": "How it Works",
    "text": "How it Works\n\nData Extraction Code:\n\nHere we use the Python environment to extract the data from different datasets using Google Earth Engine API\nAfterwards, we first use the crop-specific land cover data to distinguish different crops- wheat, soybean or corn for each county in North Dakota.\nFurther, NDVI, Precipitation, SAR, Soil Moisture & other values are used to get the county-wise values from the year 2000-2024.\nAfterwards, the Yield data is obtained from the United States Department of Agriculture for each of the years and a final dataset is obtained which has all the X Variables (NDVI,PA,SMS_AM,LST_DAY,SMS_PM,LST_NIGHT,PAR,ET) & Y variable (YIELD).\n\n\npip install earthengine-api\nimport ee\nee.AuthcessYear(year):\n    # Load the CDL dataset for the given year\n    dataset = ee.ImageCollection('USDA/NASS/CDL')\\\n                .filter(ee.Filter.date(f'{year}-01-01', f'{year}-12-31'))\\\n                .first()\n    crop_landcover = dataset.select('cropland')\n\n    # Filter for North Dakota counties\n    #`STATEFP` parameter of the dataset which provides the State FIPS code & the North Dakota value is used.\n    counties = ee.FeatureCollection('TIGER/2016/Counties')\n    nd = counties.filter(ee.Filter.eq('STATEFP', '38'))\n    \n    # Identify corn areas in North Dakota\n    #`cropland` values for different crops of our study are used Wheat, Corn & Soybean Values provided from the Cropland Table.\n    corn = crop_landcover.eq(1).Or(crop_landcover.eq(12)).Or(crop_landcover.eq(13))\n    masked_corn = crop_landcover.updateMask(corn).clipToCollection(nd)\n\n    # Calculate NDVI for corn areas using MODIS data\n    #`NDVI` parameter of the dataset and we obtain the mean over the growth period of the crop\n    NDVI_dataset = ee.ImageCollection('MODIS/061/MOD13Q1')\\\n                    .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))\n    ndvi = NDVI_dataset.select('NDVI')\n    mean_ndvi = ndvi.mean().rename('NDVI')\n    cornNDVI = mean_ndvi.updateMask(masked_corn)\n    \n    # Calculate precipitation using GRIDMET data\n    #`pr` parameter of the dataset which provides the 'Precipitation amount' in mm (daily total)\n    precipitation_dataset = ee.ImageCollection(\"IDAHO_EPSCOR/GRIDMET\")\\\n                             .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))\\\n                             .select('pr')\n    mean_precipitation = precipitation_dataset.mean().rename('PA')\n\n    # Load Radiometer Global Daily 9 km Soil Moisture AM\n    #`soil_moisture_am` & `soil_moisture_pm` parameter of the dataset which provides 'Retrieved soil moisture estimate from the\n    # disaggregated/downscaled vertical polarization brightness temperature at 9-km grid cell one at AM overpass & other at  PM overpass. in dB.\n    smap_dataset = ee.ImageCollection(\"NASA/SMAP/SPL3SMP_E/005\")\\\n                    .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))\\\n                    .select('soil_moisture_am')\n    mean_soil_moisture = smap_dataset.mean().rename('SMS_AM')\n    \n    # Load Radiometer Global Daily 9 km Soil Moisture PM\n    smapDataset_pm = ee.ImageCollection(\"NASA/SMAP/SPL3SMP_E/005\")\\\n                       .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))\\\n                       .select('soil_moisture_pm') \n    meanSoilMoisture_pm = smapDataset_pm.mean().rename('SMS_PM')\n    \n    # Load MODIS Land Surface Temperature DAY\n    #`LST_Day_1km` & `LST_Night_1km` parameter of the dataset which provides 'Daytime Land Surface Temperature' &\n    # Nighttime Land Surface Temperature' both in Kelvin (K).\n    lstDataset = ee.ImageCollection(\"MODIS/061/MOD11A1\")\\\n                   .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))\n \n    lstmean_celsius = lstDataset.select('LST_Day_1km')\\\n                                .mean()\\\n                                .multiply(0.02)\\\n                                .subtract(273.15)\\\n                                .rename('LST_DAY')\n    # Load MODIS Land Surface Temperature NIGHT\n    lstDataset_night = ee.ImageCollection(\"MODIS/061/MOD11A1\")\\\n                         .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))\n \n    lstmean_celsius_night = lstDataset_night.select('LST_Night_1km')\\\n                                              .mean()\\\n                                              .multiply(0.02)\\\n                                              .subtract(273.15)\\\n                                              .rename('LST_NIGHT')\n                         \n    # Photosynthetically Active Radiation Daily 3-Hour \n    #`GMT_1200_PAR` parameter of the dataset which provides 'Total PAR at GMT 12:00'. PAR is incident solar radiation in\n    # the visible spectrum (400-700 nanometers) and is an important variable in land-surface models having use in agriculture &\n    # other scientific applications.\n    par_12 = ee.ImageCollection(\"MODIS/061/MCD18C2\")\\\n               .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))\\\n               .select('GMT_1200_PAR')\n                        \n    mean_par_12 = par_12.mean().rename('PAR'); # Calculate the Photosynthetically Active Radiation at 12\n\n                         \n    # Net Evapotranspiration\n    # `ET` parameter of the dataset which provides 'Total evapotranspiration' in kg/m^2/8day.s.\n    netevapo = ee.ImageCollection(\"MODIS/061/MOD16A2GF\")\\\n                 .filter(ee.Filter.date(f'{year}-05-01', f'{year}-10-01'))\\\n                 .select('ET')\n                    \n    mean_netevapo = netevapo.mean().rename('ET')  # Calculate the mean Soil Moisture\n\n\n    # Combine all layers\n    combinedDataset = cornNDVI.addBands(mean_precipitation).addBands(mean_s1_vv).addBands(mean_soil_moisture).addBands(lstmean_celsius).addBands(meanSoilMoisture_pm).addBands(lstmean_celsius_night).addBands(mean_par_12).addBands(mean_netevapo)\n\n    # Reduce regions and calculate mean values over the specified areas\n    combined_mean = combinedDataset.reduceRegions(\n        collection=nd,\n        reducer=ee.Reducer.mean(),\n        scale=30,\n        tileScale=4,\n    )\n\n    # Define export parameters\n    export_params = {\n        'collection': combined_mean,\n        'description': f'combined_{year}',\n        'folder': 'GEE_Folder',\n        'fileNamePrefix': f'Combined_{year}',\n        'fileFormat': 'CSV',\n        'selectors': ['NAME', 'GEOID', 'NDVI', 'PA', 'SAR', 'SMS_AM', 'LST_DAY', 'SMS_PM', 'LST_NIGHT', 'PAR', 'ET']\n    }\n\n    # Commented the line below as I have got the data in my drive already\n    #ee.batch.Export.table.toDrive(**export_params).start()\n\n# Example of processing each year\nfor year in range(2000, 2024):\n    processYear(year)\n\n\nMethodology Code:\n\nConsidering the impact of environmental factors on crop growth within designated time constraints, our project initially explored nine parameters from the GEE database. We employed a Random Forest model to perform importance testing on these parameters for each specific crop type. Based on the results of this testing, we selected five or six key variables per crop to serve as independent variables in our predictive models. The variables in Table-1 were chosen due to their direct influence on plant growth and yield across various crops like wheat, soybeans, and corn over the period from 2015 to 2023.\n\n\n\nInterface Code:\n\nIn this section, we perform calculations on the crop layers obtained from the random forest prediction model to generate various outputs. By defining global variables, we dynamically update the crop layers based on the user’s selected year and crop type. The core functionality lies in the computation logic for the County level and Area level modes.\nIn the County level mode, a click event listener is created to provide real-time feedback on the user-selected county. The number of pixels within the county is calculated, enabling the estimation of the crop area. Utilizing historical and predicted average yield data and the current year’s average market price, the total production and total value are computed.\nIn the Area level mode extends the calculation scope to a user-defined polygon region, with a similar computation method to the County level mode. The “Clear Selected Area Button” allows users to remove unnecessary polygons in the Area level mode, enhancing usability.\nThe Interface Code is as follows :\n\n// ——————————————————————————define crop layers————————————————————————————————\nvar cropLayers = {\n  Corn: {\n    // Add layers of corn\n    '2018': ee.Image(\"projects/ee-songzimeng/assets/corn2018\"),\n    '2019': ee.Image(\"projects/ee-songzimeng/assets/corn2019\"),\n    '2020': ee.Image(\"projects/ee-songzimeng/assets/corn2020\"),\n    '2021': ee.Image(\"projects/ee-songzimeng/assets/corn2021\"),\n    '2022': ee.Image(\"projects/ee-songzimeng/assets/corn2022\"),\n    '2023': ee.Image(\"projects/ee-songzimeng/assets/corn2023\"),\n    '2024': ee.Image(\"projects/ee-songzimeng/assets/corn2024\")\n    \n  },\n  \n  Soybean: {\n    // Add layers of soybean\n\n    '2018': ee.Image(\"projects/ee-songzimeng/assets/soybean2018\"),\n    '2019': ee.Image(\"projects/ee-songzimeng/assets/soybean2019\"),\n    '2020': ee.Image(\"projects/ee-songzimeng/assets/soybean2020\"),\n    '2021': ee.Image(\"projects/ee-songzimeng/assets/soybean2021\"),\n    '2022': ee.Image(\"projects/ee-songzimeng/assets/soybean2022\"),\n    '2023': ee.Image(\"projects/ee-songzimeng/assets/soybean2023\"),\n    '2024': ee.Image(\"projects/ee-songzimeng/assets/soybean2024\")\n  },\n  \n  Wheat: {\n    // Add layers of wheat\n\n    '2018': ee.Image(\"projects/ee-songzimeng/assets/wheat2018\"),\n    '2019': ee.Image(\"projects/ee-songzimeng/assets/wheat2019\"),\n    '2020': ee.Image(\"projects/ee-songzimeng/assets/wheat2020\"),\n    '2021': ee.Image(\"projects/ee-songzimeng/assets/wheat2021\"),\n    '2022': ee.Image(\"projects/ee-songzimeng/assets/wheat2022\"),\n    '2023': ee.Image(\"projects/ee-songzimeng/assets/wheat2023\"),\n    '2024': ee.Image(\"projects/ee-songzimeng/assets/wheat2024\")\n  }\n};\n\n// -------------------------- Data  ------------------------------\nMap.setCenter(-100.55, 47.5, 7);\nMap.setOptions('SATELLITE');\n\n// clip the north dakota\nvar counties = ee.FeatureCollection('TIGER/2016/Counties');\nvar nd = counties.filter(ee.Filter.eq('STATEFP', '38'));\n\n// Formatted county name function\nvar nd = nd.map(function(feature) {\n  var name = ee.String(feature.get('NAME')).toUpperCase().replace(' ', '', 'g');\n  return feature.set('NAME', name);\n});\n\n// Show the county boundary\nvar ndCounties = ee.Image().byte().paint({\n  featureCollection: nd,\n  color: null, \n  width: 1\n});\n\n// Add the counties layer\nMap.addLayer(ndCounties, {}, 'ND Counties');\n\n/// ——————————————Function and global variables——————————————————————————\n// Function to read csv\nfunction readCsvFile(selectedYear, selectedCrop) {\n  var fileName = selectedYear +'_'+ selectedCrop;\n  var csvFile = ee.FeatureCollection('projects/ee-songzimeng/assets/' + fileName); \n\n  return csvFile;\n}\n\n// Function to fomat county name\nfunction processCountyColumn(table) {\n  var countyColumnName = 'County';\n  function processCountyName(countyName) {\n    return ee.String(countyName).toUpperCase().replace('\\\\s+', '');\n  }\n  \n  var processedCountyColumn = table.map(function(feature) {\n    var countyName = feature.get(countyColumnName);\n    var processedCountyName = processCountyName(countyName);\n    return feature.set(countyColumnName, processedCountyName);\n  });\n  \n  // return FeatureCollection\n  return processedCountyColumn;\n}\n\nvar selectedCrop='Select...';\nvar selectedYear='Select...';\nvar soybeanPrice = 11.90; // 2024 average\nvar CornPrice = 41.68; // 2024 average\nvar wheatPrice = 6.07; // 2024 average\nvar cropPrice = 0; //\n\nvar crops = {\n  'Corn': 1,\n  'Wheat': 23,\n  'Soybean': 5\n};\n\n\n// ————————————————interface——————————————————————————\n// set default year\nvar defaultYear = '2018';\n\nvar cropYieldLayer = null;\n\nvar statsLabel_1 = ui.Label('Click on County to see info:');\nvar statsLabel_2 = ui.Label('Select an area to see info:');\n\n// set original info status\nstatsLabel_1.style().set('shown', true);\nstatsLabel_2.style().set('shown', false);\n\n// Clear button to remove all selected layers\nvar drawingTools = Map.drawingTools();\nvar clearButton = ui.Button({\n  label: 'Clear Selected Area',\n  onClick: function() {\n\n    var layers = drawingTools.layers();\n\n    layers.forEach(function(layer) {\n      drawingTools.layers().remove(layer);\n    });\n\n    resultsPanel.clear();\n  },\n  style: {margin: '10px'}\n});\n\n\n// the main panel to select mode, year, croptype\nvar panel = ui.Panel({\n  widgets: [\n    \n    ui.Label('North Dakota Crop Yield', {\n      fontWeight: 'bold',\n      fontSize: '22px',\n      textAlign: 'center',\n      stretch: 'horizontal'\n      \n    }),\n    \n    ui.Label('Select Mode:'),\n    ui.Select({\n      items: ['Select...','County Level', 'Area Level'],\n      value: 'Select...',\n      onChange: function(mode) {\n        \n        // operate different \n        if (mode === 'County Level') {\n          // County Level\n          statsLabel_1.style().set('shown', true);\n          statsLabel_2.style().set('shown', false);\n          \n          // reset button\n          panel.remove(clearButton);\n          panel.add(clearButton);\n          \n          // ban polygon drawing selection\n          var drawingTools = Map.drawingTools();\n          drawingTools.setShown(false);\n          \n          //Function for getting value from image\n          var getCalculation = function(countyName, cropYieldLayer) {\n            var county = nd.filter(ee.Filter.eq('NAME', countyName)).first();\n            var countyGeometry = county.geometry();\n            \n             //print(selectedYear, selectedCrop);\n            var countyData=readCsvFile(selectedYear, selectedCrop);\n            // print(countyData);\n            countyData = processCountyColumn(countyData);\n            \n            resultsPanel.clear();\n          \n            var countStats = cropYieldLayer.reduceRegion({\n              reducer: ee.Reducer.count(),\n              geometry: countyGeometry,\n              scale: 30,\n              maxPixels: 1e9\n            });\n           //print(countStats);\n          \n            var selectedCounty = countyData.filter(ee.Filter.eq('County', countyName));\n            var averYield = selectedCounty.reduceColumns({\n            reducer: ee.Reducer.mean(),\n            selectors: ['Value']\n          });\n            //print(averYield);\n          \n            // create labels\n            var countyLabel = ui.Label({\n              value: 'County: ' + countyName,\n              style: {fontSize: '13px', padding: '0px 50px'}\n            });\n          \n            var count_sumLabel = ui.Label({\n              value: 'Calculating...',\n              style: {fontSize: '13px', padding: '0px 50px'}\n            });\n          \n          // update labels by calculating\n          // get the mean yield data\n            averYield.evaluate(function(result) {\n              var meanYield = result.mean;\n              var count_averYieldLabel = ui.Label({\n                value: 'Average Yield: ' + meanYield.toFixed(2) + ' BU/Acre', \n                style: {fontSize: '13px', padding: '0px 50px'}\n              });\n                resultsPanel.add(count_averYieldLabel);\n          });\n          \n            // calculate the area and total yield\n            countStats.get('YIELDpredicted').evaluate(function(value){\n\n              var areaInSqKm = (value / 1e6) * 900;\n              var areaInAcres = areaInSqKm * 247.105;\n              count_sumLabel.setValue('Crop Area: ' + areaInSqKm.toFixed(2) + \n                                      ' km² (' + areaInAcres.toFixed(2) + ' Acres)');\n                                      \n              averYield.evaluate(function(result) {\n                var meanYield = result.mean;\n                var totalYield = areaInAcres * meanYield;\n                var count_totalYieldLabel = ui.Label({\n                  value: 'Total Yield: ' + totalYield.toFixed(2) + ' BU', \n                  style: {fontSize: '13px', padding: '0px 50px'}\n                });\n                var yieldPrice = totalYield * cropPrice;\n                var yieldPriceLabel = ui.Label({\n                  value: 'Total Yield Value: ' + yieldPrice.toFixed(2) + ' $', \n                  style: {fontSize: '13px', padding: '0px 50px'}\n                });\n                resultsPanel.add(count_totalYieldLabel);\n                resultsPanel.add(yieldPriceLabel);\n          });\n            });\n          \n            // add the new label to sub-panel\n            resultsPanel.add(countyLabel);\n            resultsPanel.add(count_sumLabel);\n          };\n          \n          Map.unlisten()\n          \n            // create onclick function\n          Map.onClick(function(coords) {\n            \n          var point = ee.Geometry.Point(coords.lon, coords.lat);\n          var county = ee.Feature(nd.filterBounds(point).first());\n          var countyName = county.get('NAME');\n          countyName.evaluate(function(name) {\n            getCalculation(name, cropYieldLayer);\n          });\n          })\n          \n\n          // Area level\n        } else if (mode === 'Area Level') {\n\n          statsLabel_1.style().set('shown', false);\n          statsLabel_2.style().set('shown', true);\n          \n          // delet onclick monitor\n          Map.unlisten()\n          \n          //reset button\n          panel.remove(clearButton);\n          panel.add(clearButton);\n          \n          // draw polygon\n          var drawingTools = Map.drawingTools();\n          drawingTools.setShown(true);\n    \n    \n          // function under area level\n          function initializeAreaLevelMode() {\n            // create a new drawing tools\n            var drawingTools = Map.drawingTools();\n            drawingTools.setShown(true);\n            \n            drawingTools.onDraw(function(geometry) {\n              // get the polygon user drawing\n              var userPolygon = geometry;\n              \n              // calculate pixels number inside the polygon user draw\n              var pixelCount = cropYieldLayer.reduceRegion({\n                reducer: ee.Reducer.count(),\n                geometry: userPolygon,\n                scale: 30,\n                maxPixels: 1e9\n              });\n              \n              //calculate average yield user draw\n             var meanStats = cropYieldLayer.reduceRegion({\n              reducer: ee.Reducer.mean(),\n              geometry: userPolygon,\n              scale: 30,\n              maxPixels: 1e9\n            });\n              // print(meanStats)\n\n                // combined 2 results\n              var results = ee.Dictionary({\n                  meanYield: meanStats.get('YIELDpredicted'),\n                  pixelCount: pixelCount.get('YIELDpredicted')\n              });\n\n              // calculate average yield, crop area, total yield, and update labels\n              results.evaluate(function(values)  {\n                resultsPanel.clear();\n                \n              var area_sumLabel = ui.Label({\n                value: 'Calculating...',\n                style: {fontSize: '14px', padding: '0px 50px'}\n              });\n              \n              var meanYield_sumLabel = ui.Label({\n                value: 'Calculating...',\n                style:{fontSize: '14px', padding: '0px 50px'}\n              });\n              \n              var count_totalYieldLabel = ui.Label({\n                value: 'Calculating...',\n                style:{fontSize: '14px', padding: '0px 50px'}\n              });\n          \n              resultsPanel.add(area_sumLabel);\n              resultsPanel.add(meanYield_sumLabel);\n              resultsPanel.add(count_totalYieldLabel);\n          \n              meanYield_sumLabel.setValue('Average Yield: ' + values.meanYield.toFixed(2) + ' BU/Acre');\n          \n              var areaInSqKm = (values.pixelCount / 1e6) * 900;\n              var areaInAcres = areaInSqKm * 247.105;\n              area_sumLabel.setValue('Crop Area: ' + areaInSqKm.toFixed(2) + \n                                      ' km² (' + areaInAcres.toFixed(2) + ' Acres)');\n                                      \n              var totalYield = areaInAcres * values.meanYield;\n              count_totalYieldLabel.setValue('Total Yield: ' + totalYield.toFixed(2) + ' BU'); \n               \n              var yieldPrice = totalYield * cropPrice;\n              var yieldPriceLabel = ui.Label({\n                  value: 'Total Yield Value: ' + yieldPrice.toFixed(2) + ' $', \n                  style: {fontSize: '13px', padding: '0px 50px'}\n                });\n              resultsPanel.add(yieldPriceLabel);\n                \n                });\n                \n            });\n\n          }\n          initializeAreaLevelMode();\n          \n        }\n        \n      }\n    }),\n    \n    ui.Label('Select Year:'),\n    ui.Select({\n      items: ['Select...', '2018', '2019', '2020', \n                 '2021', '2022', '2023', '2024'],\n      value: 'Select...',\n      onChange: function(year) {\n        \n        // update global variable selectedYear, the year user chose\n        selectedYear = year;\n        updateMap();\n\n      }\n    }),\n    \n    ui.Label('Select Crop:'),\n    ui.Select({\n      items: ['Select...', 'Soybean', 'Corn', 'Wheat'],\n      value: 'Select...',\n      onChange: function(crop) {\n        \n        selectedCrop = crop;\n        \n        // set cropPrice according to selected \n        if (selectedCrop === 'Soybean') {\n          cropPrice = 11.90; \n        } else if (selectedCrop === 'Wheat') {\n          cropPrice = 6.07; \n        } else if (selectedCrop === 'Corn') {\n          cropPrice = 5.80; \n        } else {\n          cropPrice = 0;\n        }\n        \n        updateMap();\n        \n      }\n    }),\n    \n    statsLabel_1,\n    statsLabel_2\n  ],\n  style: {position: 'top-right'}\n});\n\nMap.add(panel);\n\n// Add a sub-panel to show calculation info\nvar resultsPanel = ui.Panel({\n  layout: ui.Panel.Layout.Flow('vertical'),\n  style: {width: '310px'} \n});\npanel.add(resultsPanel);\n\n// update new layers accoording to user's selection\nfunction updateMap() {\n\n  // // Remove particular layers\n  // Map.layers().forEach(function(layer) {\n  //   var layerName = layer.getName();\n  //   if (layerName.indexOf('YIELD_') === 0) {\n  //     Map.remove(layer);\n  //   }\n  // });\n  \n  Map.layers().reset();\n\n  // Show layers if user choose both selections\n  if (selectedYear !== 'Select...' && selectedCrop !== 'Select...') {\n    \n      cropYieldLayer = cropLayers[selectedCrop][selectedYear];\n\n    if (cropYieldLayer) {\n      var layerName = selectedCrop + '_' + selectedYear;\n      Map.addLayer(cropYieldLayer, {}, 'YIELD_' + layerName);\n    }\n\n  }\n  \n  // add the counties layer\n  Map.addLayer(ndCounties, {}, 'ND Counties');\n}\n\nFirst, we experimented with various machine learning methods in Python, including Linear Regression (LR), Random Forest Regressor (RF), Gradient Boosting Regressor (XGB), and Artificial Neural Network (ANN). By comparing their R2 and RMSE scores, we identified the most suitable method for each of the three crops.\nConsidering the impact of environmental factors on crop growth within a specified time frame, we initially explored all nine parameters. Subsequently, based on the importance tests from the Random Forest model, five to six key variables were selected as independent variables in the predictive models for each crop.\nIn GEE, we trained Random Forest (RF) predictive models separately for three types of crops using data from six years, spanning 2018 to 2023, and split them into training/validation datasets. After obtaining the models, we assessed their performance using R2 and RMSE.\nUsing the historical average method to make a simple prediction for the crop yield of the coming year.\n\n#install packages\n!pip install tensorflow\n\n#load packages\n\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\n#packages for manipulating dataframe\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nfrom shapely.geometry import Point\nimport sklearn\n\n#packages for machine learning\n##train-test-split\nfrom sklearn.model_selection import train_test_split, GridSearchCV, validation_curve\n\n##method 1: Linear Regression (LR)\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import cross_val_score\n\n##method 2: Random Forest Regressor (RF)\nimport rfpimp\nfrom sklearn.ensemble import RandomForestRegressor\n\n##method 3: Gradient Boosting Regressor (XGB)\nimport xgboost\nfrom xgboost import XGBRegressor\n\n##method 4: Artificial Neural Network (ANN)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n##cross validation\n\n##evaluation metrics (R2 and RMSE)\nfrom sklearn.metrics import r2_score, mean_squared_error\n\n#data visualization\nimport matplotlib.pyplot as plt\n\npd.set_option('display.max_rows', 300) # specifies number of rows to show\npd.options.display.float_format = '{:40,.4f}'.format # specifies default number format to 4 decimal places\nplt.style.use('ggplot') # specifies that graphs should use ggplot styling\n%matplotlib inline\n\n# 1. Load & Cleaning Data\n#load data\nsoybean_2018 = pd.read_csv('https://www.dropbox.com/scl/fi/ixibqk9pyuehwvoz7mr1h/2018_County_Summary_Merged.csv?rlkey=wueodqdvzsht5or4eftwdd3ys&dl=1')\nsoybean_2019 = pd.read_csv('https://www.dropbox.com/scl/fi/x3oiqrikr0xagqrh5tiqu/2019_County_Summary_Merged.csv?rlkey=zr5wru8sg5iybp43lnjf7ls5a&dl=1')\nsoybean_2020 = pd.read_csv('https://www.dropbox.com/scl/fi/m4r74ydgw3yno93nakagl/2020_County_Summary_Merged.csv?rlkey=kmd8bozo9z9jxznoa775gg33z&dl=1')\nsoybean_2021 = pd.read_csv('https://www.dropbox.com/scl/fi/2vmvsyjloz9hvzejtdez4/2021_County_Summary_Merged.csv?rlkey=ossgr4x3fvzgebhqprchntt2f&dl=1')\nsoybean_2022 = pd.read_csv('https://www.dropbox.com/scl/fi/x61224yvwtq4idnqphwjy/2022_County_Summary_Merged.csv?rlkey=s3zm9ooap8pjqom3jr0aklc6t&dl=1')\nsoybean_2023 = pd.read_csv('https://www.dropbox.com/scl/fi/zrjnmeqysrokfsua24hb3/2023_County_Summary_Merged.csv?rlkey=jb4w1pt295zeagbvgm7c2t7pk&dl=1')\n\nsoybean_list = [soybean_2018, soybean_2019, soybean_2020, soybean_2021, soybean_2022, soybean_2023]\nsoybean_df = pd.concat(soybean_list)\nsoybean_df = soybean_df.drop(['NAME','GEOID','SMS_PM','SMS_AM','SAR'], axis=1)\nsoybean_df.info()\n\n# 2.1 Train & Test Data Split\n#split the dataset\nX = soybean_df.drop('YIELD', axis=1)\ny = soybean_df['YIELD']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)\n\n# 2.2 Train & Test Data Standarderlized\ndef standardize_columns(file_name, columns_to_standardize):\n    scaler = StandardScaler()\n\n    df = file_name\n    df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n    return df\n\ndef standardize_series(series):\n    scaler = StandardScaler()\n    series = scaler.fit_transform(series.values.reshape(-1, 1)).flatten()\n    return series\n    \nX_columns = ['LST_DAY','PA','NDVI','ET','LST_NIGHT','PAR']\ny_columns = ['YIELD']\n\nX_train = standardize_columns(X_train, X_columns)\nX_test = standardize_columns(X_test, X_columns)\n\n# 3. Model Training and Parameter Tuning\n# 3.1. Linear Regression (LR)\nmodel_lr = LinearRegression()\n\n# Cross validation\nscores = cross_val_score(model_lr, X, y, cv=5, scoring='neg_mean_squared_error')\n\nmean_mse = np.mean(scores)\nstd_mse = np.std(scores)\n\nprint(f'Mean MSE: {mean_mse}')\nprint(f'Standard Deviation of MSE: {std_mse}')\nmodel_lr.fit(X_train, y_train)\n\n# 3.2. Random Forest Regressor (RF)\n# values of max_depth and min_samples_split\nhyperparameters = {'max_depth':[3,5,10,20,30], 'min_samples_split':[2,4,6,8,10]}\n\n\nrandomState_dt = 10000\nmodel_rf = RandomForestRegressor(random_state=randomState_dt)\n\n# cv=5 by default, which means 5-fold cross-validation\nclf = GridSearchCV(model_rf, hyperparameters)\n\nclf.fit(X_train, y_train)\n\n# we can query the best parameter value and its accuracy score\nprint (\"The best parameter value is: \")\nprint (clf.best_params_)\nprint (\"The best score is: \")\nprint (clf.best_score_)\n\n# Train the final RF\nrf_final = RandomForestRegressor(max_depth=clf.best_params_['max_depth'], min_samples_split=clf.best_params_['min_samples_split'], random_state=randomState_dt)\nrf_final.fit(X_train, y_train)\n\n# 3.3. Gradient Boosting Regressor (XGB)\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n# values of max_depth and min_samples_split\nhyperparameters = {'max_depth':[2,4,6,8,10], 'n_estimators':[4,8,12,16,20]}\n\nrandomState_xgb = 125\nxgb = XGBRegressor(random_state=randomState_xgb)\n\n# cv=5 by default, which means 5-fold cross-validation\ngscv_xgb = GridSearchCV(xgb, hyperparameters)\n\ngscv_xgb.fit(X_train, y_train)\n\n# we can query the best parameter value and its accuracy score\nprint (\"The best parameter value is: \")\nprint (gscv_xgb.best_params_)\nprint (\"The best score is: \")\nprint (gscv_xgb.best_score_)\n\n# 3.4. Artificial Neural Network (ANN)\nmodel_ann = keras.Sequential([\n    layers.Input(shape=(6,)),  # Input layer\n    layers.Dense(128, activation='relu'),  # Hidden layer with ReLU activation\n    layers.Dropout(0.5),  # Dropout layer for regularization\n    layers.Dense(64, activation='relu'),  # Additional hidden layer\n    layers.Dropout(0.3),  # Another dropout layer\n    layers.Dense(1)  # Output layer\n])\n\n#measuring the training with certain metrics\nmodel_ann.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n\n#train the model\nmodel_ann.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n\n# 4. Model Evaluation and Performance Comparison\n# 4.1. E. Linear Regression (LR)\ntrain_predictions = model_lr.predict(X_train)\ntest_predictions = model_lr.predict(X_test)\n\nr2_train_lr = r2_score(y_train, train_predictions)\nr2_test_lr = r2_score(y_test, test_predictions)\n\nrmse_train_lr = mean_squared_error(y_train, train_predictions, squared=False)\nrmse_test_lr = mean_squared_error(y_test, test_predictions, squared=False)\n\nprint(f\"Training R^2: {r2_train_lr:.4f}\")\nprint(f\"Test R^2: {r2_test_lr:.4f}\")\nprint(f\"Training RMSE: {rmse_train_lr:.4f}\")\nprint(f\"Test RMSE: {rmse_test_lr:.4f}\")\n\n# 4.2. E. Random Forest Regressor (RF)\nr2_train_rf = rf_final.score(X=X_train, y=y_train)\nr2_test_rf = rf_final.score(X=X_test, y=y_test)\n\nprint(\"R2 on the training data:\")\nprint(r2_train_rf)\nprint(\"R2 on the testing data:\")\nprint(r2_test_rf)\n\nrmse_train_rf = mean_squared_error(y_train, rf_final.predict(X_train), squared=False)\nrmse_test_rf = mean_squared_error(y_test, rf_final.predict(X_test), squared=False)\n\nprint(\"RMSE on the training data:\")\nprint(rmse_train_rf)\nprint(\"RMSE on the testing data:\")\nprint(rmse_test_rf)\n\n# Calculate and plot the feature importance of the RF model\nimp = rfpimp.importances(rf_final, X_test, y_test)\nprint(imp)\nviz = rfpimp.plot_importances(imp)\nviz.view()\n\n# 4.3. E. Gradient Boosting Regressor (XGB)\nmodel_xgb = XGBRegressor(max_depth=gscv_xgb.best_params_['max_depth'], n_estimators=gscv_xgb.best_params_['n_estimators'], random_state=randomState_xgb)\nmodel_xgb.fit(X_train, y_train)\n\n# r2_train_xgb, r2_test_xgb, rmse_train_xgb, rmse_test_xgb\nr2_train_xgb = model_xgb.score(X=X_train, y=y_train)\nr2_test_xgb = model_xgb.score(X=X_test, y=y_test)\nrmse_train_xgb = mean_squared_error(y_train, model_xgb.predict(X_train), squared=False)\nrmse_test_xgb = mean_squared_error(y_test, model_xgb.predict(X_test), squared=False)\n\nprint(\"R2 on the training data:\")\nprint(r2_train_xgb)\nprint(\"R2 on the testing data:\")\nprint(r2_test_xgb)\n\nprint(\"RMSE on the training data:\")\nprint(rmse_train_xgb)\nprint(\"RMSE on the testing data:\")\nprint(rmse_test_xgb)\n\nimp_xgb = rfpimp.importances(model_xgb, X_test, y_test) # permutation\nprint(imp_xgb)\nviz_xgb = rfpimp.plot_importances(imp_xgb)\nviz_xgb.view()\n\n# 4.4. E. Artificial Neural Network (ANN)\n#predictions\ny_pred_train_ann = model_ann.predict(X_train).flatten()\ny_pred_test_ann = model_ann.predict(X_test).flatten()\n\n#Compute R2 and RMSE\nr2_train_ann = np.round(r2_score(y_train, y_pred_train_ann),2)\nr2_test_ann = np.round(r2_score(y_test, y_pred_test_ann),2)\nrmse_train_ann = np.round(np.sqrt(mean_squared_error(y_train, y_pred_train_ann)),2)\nrmse_test_ann = np.round(np.sqrt(mean_squared_error(y_test, y_pred_test_ann)),2)\n\n#print the result\nprint(\"Train R2:\", r2_train_ann)\nprint(\"Test R2:\", r2_test_ann)\nprint(\"Train RMSE:\", rmse_train_ann)\nprint(\"Test RMSE:\", rmse_test_ann)\n\n#crosscheck the y value between real and predicted\ncrosscheck_y_dict = {\n    'y_test' : y_test,\n    'y_pred' : np.round(y_pred_test_ann,0),\n    'delta' : np.abs(np.round((y_test - y_pred_test_ann),0))\n}\n\n#plotting histogram\ncrosscheck_y_df = pd.DataFrame(crosscheck_y_dict)\nplt.hist(crosscheck_y_df['delta'], bins=10)\nplt.xlabel(f'Delta\\nR2_test = {r2_test_ann}, RMSE_test = {rmse_test_ann}, delta_max = {crosscheck_y_df.delta.max()}')\nplt.ylabel('Frequency (Number of Data)')\nplt.title(f\"Accuracy of ANN Model Based on Delta of Y Test and Y Pred)\")\nplt.show()\n\n# 4.5. Model Performance Comparison\n#please input your metrics in here\nmetrics_dict = {\n    'metrics': [\"Train R2\",\"Test R2\",\"Train RMSE\",\"Test RMSE\"],\n    'LR': [r2_train_lr, r2_test_lr, rmse_train_lr, rmse_test_lr],\n    'RF': [r2_train_rf, r2_test_rf, rmse_train_rf, rmse_test_rf],\n    'XGB': [r2_train_xgb, r2_test_xgb, rmse_train_xgb, rmse_test_xgb],\n    'ANN': [r2_train_ann, r2_test_ann, rmse_train_ann, rmse_test_ann]\n}\n\n#create dataframe\nmetrics_df = pd.DataFrame(metrics_dict)\nmetrics_df.set_index('metrics')"
  }
]